{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and preprocessing. replace the missing value with mean and deal with categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 51.8442300821722, 17: 4.672150238473764, 19: 2.0249661399548584, 21: 109.07240061162081, 23: 0.9979121054734302, 25: 110.78798403193613}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy\n",
    "import scipy\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "data_list=[]\n",
    "y=[]\n",
    "data=csv.reader(open('/Users/wendy/Documents/2017 Fall/CS 534/HW4/allhyper.data'))\n",
    "for row in data:\n",
    "    data_list.append(row)\n",
    "features=deepcopy(data_list[0])\n",
    "data_list.pop(0)\n",
    "\n",
    "####convert string to int\n",
    "for i in range(len(data_list)):\n",
    "    if data_list[i][29]=='negative.':\n",
    "        data_list[i][29]=0\n",
    "    else:\n",
    "        data_list[i][29]=1\n",
    "############\n",
    "for i in range(len(data_list)):\n",
    "    if data_list[i][1]=='F':\n",
    "        data_list[i][1]=1\n",
    "    elif data_list[i][1]=='M':\n",
    "        data_list[i][1]=2\n",
    "    else:\n",
    "        data_list[i][1]=0\n",
    "index_list=(2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,20,22,24,26)\n",
    "for i in index_list:\n",
    "    for j in range(len(data_list)):\n",
    "        \n",
    "        if data_list[j][i]=='f':\n",
    "            data_list[j][i]=0\n",
    "        else:\n",
    "            data_list[j][i]=1\n",
    "############\n",
    "class_mean={}\n",
    "def calculate_mean(n):\n",
    "    sum=0\n",
    "    index=0\n",
    "    for i in range(len(data_list)):\n",
    "        if data_list[i][n]!='NA':\n",
    "            sum+=float(data_list[i][n])\n",
    "            index+=1\n",
    "    return sum/index\n",
    "class_mean[0]=calculate_mean(0)\n",
    "class_mean[17]=calculate_mean(17)\n",
    "class_mean[19]=calculate_mean(19)\n",
    "class_mean[21]=calculate_mean(21)\n",
    "class_mean[23]=calculate_mean(23)\n",
    "class_mean[25]=calculate_mean(25)\n",
    "print class_mean\n",
    "feature_list=(0,17,19,21,23,25)\n",
    "for i in feature_list:\n",
    "    for j in range(len(data_list)):\n",
    "        if data_list[j][i]=='NA':\n",
    "            data_list[j][i]=class_mean[i]\n",
    "################            \n",
    "whole_data=numpy.array(data_list)\n",
    "\n",
    "trainx=whole_data[0:int(0.7*len(whole_data)),0:26].astype(float)\n",
    "trainy=whole_data[0:int(0.7*len(whole_data)),29].astype(float)\n",
    "testx=whole_data[int(0.7*len(whole_data)):len(whole_data),0:26].astype(float)\n",
    "testy=whole_data[int(0.7*len(whole_data)):len(whole_data),29].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cross validation to find the optimal parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000379269019073 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "r=numpy.logspace(-5,5,num=20)\n",
    "h=numpy.arange(10)\n",
    "best_score=0\n",
    "for a in r:\n",
    "    for b in h:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=a,hidden_layer_sizes=(b+1,), random_state=1)\n",
    "        clf.fit(trainx,trainy)\n",
    "        scores = cross_val_score(clf, trainx,trainy, scoring='accuracy',cv=5)\n",
    "        score_mean=max(scores)\n",
    "        if score_mean>best_score:\n",
    "            best_score=score_mean\n",
    "            best_alpha=a\n",
    "            best_hidden=b+1\n",
    "print best_alpha,best_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# claculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976218787158\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=0.000379269019073,hidden_layer_sizes=(10,), random_state=1)\n",
    "clf.fit(trainx,trainy)\n",
    "prediction=clf.predict(testx)\n",
    "err=0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i]!=testy[i]:\n",
    "        err+=1\n",
    "print  1-float(err)/len(testy)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare the accuracy ,f1,f2score between Neuron Network, linear SVM and Random forset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "f1=f1_score(testy, prediction, average='weighted')  \n",
    "f2=fbeta_score(testy, prediction, average='weighted',beta=0.5)\n",
    "print f1,f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|         |accuracy|f1 score|f2 score|\n",
    "| ------------- |:-------------:|\n",
    "|NN|0.976218787158|0.972037778073|0.971954609589|\n",
    "|linear SVM|0.9872383869321082|0.977142080437|0.986775456095|\n",
    "|Random forest|0.985493230174|0.978256985439|0.977782966194|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As shown in the table, SVM and Random forset overall has a better performance than NN, higher accuracy,higher f1 score and f2 score.However HH has less parameter to train and requires less computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
